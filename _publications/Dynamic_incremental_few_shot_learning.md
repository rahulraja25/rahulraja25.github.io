---
title: " Weakly Supervised Few-shot Object Segmentation using Co-Attention with Visual and Semantic Inputs "
collection: publications
permalink: /publication/Dynamic_incremental_few_shot_learning
date: 2019-11-15
venue: 'IJCAI 2020'
citation: 'Mennatullah Siam*, <b>Naren Doraiswamy*</b>, Boris Oreshkin*, Hengshuai Yao, Martin Jagersand.(2019). <i>Accepted in IJCAI 2020</i>.'
---
[[PDF]](https://arxiv.org/abs/2001.09540)


Significant progress has been made recently in developing few-shot object segmentation methods. Learning is shown to be successful in few-shot segmentation settings, using pixel-level, scribbles and bounding box supervision. This paper takes another approach, i.e., only requiring image-level label for few-shot object segmentation. We propose a novel multi-modal interaction module for few-shot object segmentation that utilizes a co-attention mechanism using both visual and word embedding. Our model using image-level labels achieves 4.8% improvement over previously proposed image-level few-shot object segmentation. It also outperforms state-of-the-art methods that use weak bounding box supervision on PASCAL-5i. Our results show that few-shot segmentation benefits from utilizing word embeddings, and that we are able to perform few-shot segmentation using stacked joint visual semantic processing with weak image-level labels. We further propose a novel setup, Temporal Object Segmentation for Few-shot Learning (TOSFL) for videos. TOSFL can be used on a variety of public video data such as Youtube-VOS, as demonstrated in both instance-level and category-level TOSFL experiments.
